---
title: "Filter check"
output: beamer_presentation
---

```{r setup}
# source("install_packages.R")

library(magrittr)
library(tidyverse)
library(glue)
library(Biostrings)
library(ShortRead)
library(ggplot2)
library("scales")

#if (interactive()) {
  base.dir <- getwd() %>%
    str_extract(".*oueme-fungi-transect")
  data.dir <- file.path(base.dir, "data")
  lab.dir <- file.path(base.dir, "config")
  seq.dir <- file.path(base.dir, "sequences")
  rawfastq.dir <- file.path(seq.dir, "rawfastq")
  demux.dir <- file.path(seq.dir, "demux")
  trim.dir <- file.path(seq.dir, "trim")
  dataset.file <- file.path(lab.dir, "datasets.csv")
  datasets <- read_csv(dataset.file)
  
  
#}
```

```{r}

reads <- datasets %>%
  mutate(
    trim.files = map(
      paste0(seq_run, ".*\\.fastq\\.gz"),
      list.files,
      path = trim.dir,
      full.names = TRUE
    ),
    old.demux.files = map(
      paste0(dataset, ".*\\.fastq\\.gz"),
      list.files,
      path = demux.dir,
      full.names = TRUE
    ),
    files = pmap(
      list(trim.files, old.demux.files),
      c
    )
  ) %>%
  select(-trim.files, -old.demux.files) %>%
  unnest() %>%
  filter(!str_detect(files, "-x[a-z]{2}\\.fastq\\.gz")) %>%
  mutate(filesize = file.size(files),
         base_calling = ifelse(str_detect(basename(files), seq_run),
                               "arrow", "default")) %>%
  filter(filesize > 0,
         base_calling == "default" | tech == "PacBio") %>%
  mutate(fastq = map(files, readFastq),
         # fastq = map(fastq, ~magrittr::extract(., width(.) > 0)),
         eexp = map(fastq, ~ 10^(-1 * as(.@quality, "matrix")/10) %>%
                      rowSums(na.rm = TRUE)),
         p.noerr = map(fastq, ~log1p(- 10^(-1 * as(.@quality, "matrix")/10)) %>%
                         rowSums(na.rm = TRUE) %>%
                         exp),
         length = map(fastq, width)) %>%
  select(-fastq) %>%
  unnest() %>%
  mutate(erate = eexp/length)
```

```{r}
reverselog_trans <- function(base = exp(1)) {
    trans <- function(x) -log(x, base)
    inv <- function(x) base^(-x)
    trans_new(paste0("reverselog-", format(base)), trans, inv, 
              log_breaks(base = base), 
              domain = c(1e-100, Inf))
}

ggplot(reads, aes(x = erate,
                  # group = paste(base_calling, dataset),
                  color = dataset,
                  linetype = base_calling)) +
  geom_step(aes(y = 1- ..y..), stat = "ecdf") +
  scale_x_continuous(name = "Expected number of errors per base",
                     trans = reverselog_trans(10),
                     limits = c(NA, 1e-5),
                     oob = squish) +
  scale_y_continuous(name = "Fraction passing")

ggplot(reads, aes(x = eexp,
                  group = paste(base_calling, dataset),
                  color = dataset,
                  linetype = base_calling)) +
  geom_step(aes(y = 1- ..y..), stat = "ecdf") +
  scale_x_continuous(name = "Expected number of errors",
                     trans = reverselog_trans(10),
                     limits = c(NA, 0.1),
                     oob = squish) +
  scale_y_continuous(name = "Fraction passing")

ggplot(reads, aes(x = p.noerr,
                  group = paste(base_calling, dataset),
                  color = dataset,
                  linetype = base_calling)) +
  geom_step(aes(y = 1 - ..y..), stat = "ecdf") +
  scale_x_continuous(name = "Expectation of being error-free",
                     # trans = log_trans(10),
                     limits = c(0, 1),
                     oob = squish) +
  scale_y_continuous(name = "Fraction passing")

ggplot(reads, aes(x = length,
                  group = paste(base_calling, dataset),
                  color = dataset,
                  linetype = base_calling)) +
  geom_step(aes(y = 1- ..y..), stat = "ecdf") +
  scale_x_log10(name = "Length (bp)") +
  scale_y_continuous(name = "Fraction Greater than length")
  

reads %>%
  group_by(base_calling, dataset) %>%
  summarize(`Expected Error-Free` = sum(p.noerr),
            Total = n()) %>%
  knitr::kable()
```

```{r}
library(dada2)
dada2::plotQualityProfile(unique(filter(reads, Tech == "PacBio")$files))
```


```{r}
counts <- read_csv(file.path(data.dir, "fastq.counts"), col_names = c("file", "reads"))
counts %<>% mutate(dataset = map(file, str_extract, datasets$dataset) %>%
                     map_chr(purrr::compose(dplyr::first, sort, unique)),
                   seq.run = map(file, str_extract, datasets$seq_run) %>%
                     map_chr(purrr::compose(dplyr::first, sort, unique)),
                   well = str_extract(file, "[A-H]\\d\\d?"),
                   shard = str_extract(file, "\\bx[a-z][a-z]\\b"),
                   is.shard = !is.na(shard),
                   region = str_extract(file, "(ITS[12]|LSU)"),
                   is.trim = str_detect(file, "trim"),
                   is.demux = is.na(region) & !is.trim & !is.na(well),
                   type = ifelse(is.trim, "trim",
                                 ifelse(!is.na(region), "ITSx",
                                        ifelse(is.demux, "demux",
                                               "original"))),
                   plate = str_extract(file, "00\\d") %>% replace_na("001")) %>%
  group_by(dataset, type, plate, region, is.shard) %>%
  summarize(reads = sum(reads)) %>%
  ungroup() %>%
  select(-is.shard) %>%
  unique() %>%
  spread(key = "type", value = "reads") %>%
  select(dataset, plate, original, demux, region, ITSx, trim) %>%
  filter(!is.na(dataset)) %>%
  group_by(dataset) %>%
  mutate(original = na.omit(original),
         demux = na.omit(demux)) %>%
  filter(all(is.na(region)) | !is.na(region)) %>%
  ungroup()

demux.counts <- read_lines(file.path(data.dir, "demux.counts")) %>%
  str_match("([^:]+): (\\d+) sequences ([^(]+)( \\(([FR]): (\\d+), ([FR]): (\\d+)\\))?\\.") %>%
  magrittr::extract(,c(2,3,4,6,7,8, 9)) %>%
  set_colnames(c("file", "reads", "type", "d1", "n1", "d2", "n2")) %>%
  as_tibble() %>%
  mutate_at(c("reads", "n1", "n2"), as.integer) %>%
  mutate(fwd = case_when(!is.na(d1) & d1 == "F" ~ n1,
                         !is.na(d2) & d2 == "F" ~ n2,
                         TRUE ~ NA_integer_),
         rev = case_when(!is.na(d1) & d1 == "R" ~ n1,
                         !is.na(d2) & d2 == "R" ~ n2,
                         TRUE ~ NA_integer_)) %>%
  select(-(d1:n2)) %>%
  mutate(dataset = map(file, str_extract, datasets$dataset) %>%
           map_chr(purrr::compose(dplyr::first, sort, unique)),
         seq.run = map(file, str_extract, datasets$seq_run) %>%
           map_chr(purrr::compose(dplyr::first, sort, unique)),
         seq.plate = map(file, str_extract, paste0(datasets$dataset, "-[0-9]{3}")) %>%
           map_chr(purrr::compose(dplyr::first, sort, unique))) %>%
  group_by(dataset, seq.run, seq.plate,type) %>%
  summarize_at(c("reads", "fwd", "rev"), sum) %>%
  ungroup() %>%
  mutate(type = recode(type,
                       "with at least one tag match" = "any.tag",
                       "match at least 90% of tag length" = "tag.cover",
                       "with at most 3 tag mismatches" = "tag.score",
                       "with no more than one distinct tag in each direction" = "identifiable",
                       "with tags in both directions" = "both.tags",
                       "with tags appearing in correct order" = "tag.order")) %>%
  gather(key = "dir", value = "reads", reads, fwd, rev) %>%
  mutate_at("dir", str_replace, "^reads$", "") %>%
  tidyr::unite("type", type, dir, sep = ".") %>%
  spread(key = "type", value = "reads") %>%
  set_names(str_replace(names(.), "\\.$", "")) %>%
  keep(~!all(is.na(.))) %>%
  select(dataset, starts_with("any.tag"), starts_with("tag.cover"),
         starts_with("tag.score"), starts_with("identifiable"), both.tags, tag.order) %>%
  left_join(select(counts, dataset, original, demux) %>%
              filter(complete.cases(.)) %>%
              unique()) %>%
  select(dataset, original, any.tag:tag.order, demux) %>%
  left_join(select(counts, dataset, region, ITSx, trim))

dada.counts <-
  demux.counts %>%
  left_join(select(datasets, dataset = dataset, seq_run)) %>%
  mutate(file = glue("{data.dir}/{dataset}_{seq_run}.dada.seqtable.rds"),
         file = ifelse(is.na(region),
                       file,
                       str_replace(file, "\\.dada", glue(".{region}.dada"))),
         seq.tab = map(file, readRDS),
         assigned = map_int(seq.tab, sum),
         n_ASV = map_int(seq.tab, ncol),
         file = str_replace(file, "\\.dada\\.seqtable\\.rds",
                            ".dada.nochim.rds"),
         nochim = map(file, readRDS),
         nochim.reads = map_int(nochim, sum),
         nochim.ASV = map_int(nochim, ncol)) %>%
  select(-seq.tab, -file, -nochim)
         
dada.counts
```
```{r}
s.pb.seqs <- readRDS(glue("{data.dir}/short-pacbio_pb_483.dada.nochim.rds")) %>%
  colSums %>%
  tibble(seq = names(.),
         pb.reads = .)
s.ion.seqs <- readRDS(glue("{data.dir}/short-ion_is_057.dada.nochim.rds")) %>%
  colSums %>%
  tibble(seq = names(.),
         ion.reads = .)

(crosstab <- full_join(s.pb.seqs, s.ion.seqs, by = "seq") %>%
  mutate(len = str_length(seq)) %>%
  replace_na(list(pb.reads = 0, ion.reads = 0))) %>%
  ggplot(aes(x = ion.reads, y = pb.reads, color = len)) +
  geom_point() +
  scale_y_log10() +
  scale_x_log10()
```

IonTorrent reads which match a PacBio ASV: `r filter(crosstab, pb.reads > 0) %$% sum(ion.reads)`
IonTorrent reads which do NOT match PacBio: `r filter(crosstab, pb.reads == 0) %$% sum(ion.reads)`
PacBio reads which match an IonTorrent ASV: `r filter(crosstab, ion.reads > 0) %$% sum(pb.reads)`
PacBio reads which do NOT match IonTorrent: `r filter(crosstab, ion.reads == 0) %$% sum(pb.reads)`

```{r}
crosstab %>% arrange(pb.reads, ion.reads) %>%
  write.csv(file.path(data.dir, "pb_vs_ion_ASVs.csv"))
```

```{r}
demux.counts %>%
  select(dataset, region) %>%
  left_join(select(datasets, dataset = dataset, seq_run)) %>%
  mutate(file = glue("{data.dir}/{dataset}_{seq_run}.dada.taxonomy.rds"),
         file = ifelse(is.na(region),
                       file,
                       str_replace(file, "\\.dada", glue(".{region}.dada")))) %>%
  filter(file.exists(file)) %>%
  mutate(tax = map(file, readRDS)) %>%
  unnest %>%
  filter(str_detect(Taxonomy, "Inocybe")) %>%
  mutate(nreads = rowSums(select_if(., is.integer), na.rm = TRUE)) %>%
  arrange(desc(nreads)) %>%
  select(dataset, region, nreads, Taxonomy, seq) %>%
  mutate(name = paste(dataset, region, substr(map_chr(seq, digest::digest, algo = "sha1"), 1, 8), sep = "_")) %$%
  set_names(seq, name) %>%
  DNAStringSet(use.names = TRUE) %>%
  writeFasta(file.path(data.dir, "inocybe.fasta"))

`short-ion_is_057.dada.nochim` %>%
  colnames() %>%
  set_names(paste0("seq", seq_along(.))) %>%
  DNAStringSet(use.names = TRUE) %>%
  writeFasta(file.path(data.dir, "short-ion.fasta"))
```

