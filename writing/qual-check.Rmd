---
title: "Read quality check"
output:
  beamer_presentation:
    latex_engine: xelatex
---

```{r setup, include = FALSE}
library(magrittr)
library(tidyverse)
library(glue)
library(Biostrings)
library(ShortRead)
library(ggplot2)
library("scales")
library(drake)
knitr::opts_chunk$set(echo = FALSE, device = "tikz")
theme_set(theme_bw(base_size = 24) + theme(legend.direction = "vertical"))
```

```{r include=FALSE}
datasets <- readd(datasets)
# xdata <- readd(itsxtrim_.its1.lr5.)
# pos <- readd(positions_pb500002A1f)
reads <- readd(qstats_join) %>%
  mutate_at("Region", factor,
            levels = c("ITS2", "ITS1", "short", "ITS", "LSU", "long")) %>%
  mutate_at("Dataset", factor,
            levels = c("short-ion", "short-pacbio", "long-pacbio")) %>%
  group_by(Dataset, Plate, Region)
reads_subset <- reads %>%
  do(if (nrow(.) > 10000) sample_n(., 10000) else .)
summarize(reads, n = n())
```



```{r}
reverselog_trans <- function(base = exp(1)) {
    trans <- function(x) -log(x, base)
    inv <- function(x) base^(-x)
    trans_new(paste0("reverselog-", format(base)), trans, inv, 
              log_breaks(base = base), 
              domain = c(1e-100, Inf))
}
```

## Minimum quality score
```{r}
ggplot(reads_subset, aes(x = minq,
                  linetype = Dataset,
                  group = paste(Dataset, Region),
                  color = Region)) +
  geom_line(aes(y = 1 - ..y..), stat = "ecdf") +
  scale_x_continuous(name = "Minimum quality score",
                     # trans = reverselog_trans(10),
                     # limits = c(NA, 1e-5),
                     oob = squish) +
  scale_y_continuous(name = "Fraction passing") +
  scale_color_viridis_d(option = "C") +
  scale_linetype_discrete()
```

## Expected error rate
```{r}

ggplot(reads_subset, aes(x = erate,
                  linetype = Dataset,
                  group = paste(Dataset, Region),
                  color = Region)) +
  geom_line(aes(y = 1 - ..y..), stat = "ecdf") +
  scale_x_continuous(name = "Expected number of errors per base",
                     trans = reverselog_trans(10),
                     limits = c(NA, 1e-5),
                     oob = squish) +
  scale_y_continuous(name = "Fraction passing") +
  scale_color_viridis_d(option = "C") +
  scale_linetype_discrete()
```

## Expected number of errors
```{r}
ggplot(reads_subset, aes(x = eexp,
                  linetype = Dataset,
                  group = paste(Dataset, Region),
                  color = Region)) +
  geom_line(aes(y = 1 - ..y..), stat = "ecdf") +
  scale_x_continuous(name = "Expected number of errors",
                     trans = reverselog_trans(10),
                     limits = c(NA, 0.1),
                     oob = squish) +
  scale_y_continuous(name = "Fraction passing") +
  scale_color_viridis_d(option = "C") +
  scale_linetype_discrete()
```

## Error-free probability

```{r}
ggplot(reads_subset, aes(x = p.noerr,
                  linetype = Dataset,
                  group = paste(Dataset, Region),
                  color = Region)) +
  geom_line(aes(y = 1 - ..y..), stat = "ecdf") +
  scale_x_continuous(name = "Expectation of being error-free",
                     # trans = log_trans(10),
                     limits = c(0, 1),
                     oob = squish) +
  scale_y_continuous(name = "Fraction passing") +
  scale_color_viridis_d(option = "C") +
  scale_linetype_discrete()
```

## Read length

```{r}
ggplot(reads_subset, aes(x = length,
                  linetype = Dataset,
                  group = paste(Dataset, Region),
                  color = Region)) +
  geom_line(aes(y = 1 - ..y..), stat = "ecdf") +
  scale_x_log10(name = "Length (bp)",
                limits = c(50, NA),
                oob = squish) +
  scale_y_continuous(name = "Fraction Greater than length") +
  scale_color_viridis_d(option = "C") +
  scale_linetype_discrete()
```

## Read length density
```{r}
ggplot(reads_subset, aes(x = length,
                  linetype = Dataset,
                  group = paste(Dataset, Region),
                  color = Region)) +
  geom_line(stat = "density") +
  scale_x_log10(name = "Length (bp)",
                limits = c(50, NA),
                oob = squish) +
  scale_y_continuous(name = "count") +
  scale_color_viridis_d(option = "C") +
  scale_linetype_discrete()
```

## Expected error-free reads
```{r}
reads %>%
  group_by(Dataset, Plate, Region) %>%
  summarize(`Expected Error-Free` = sum(p.noerr),
            Total = n()) %>%
  knitr::kable()
```

```{r eval = FALSE}
library(dada2)
dada2::plotQualityProfile(unique(filter(reads, Tech == "PacBio")$files))
```


```{r eval = FALSE}
counts <- readd(seq_counts) %>% 
  tidyr::extract(col = "file",
                     into = c("Seq.Run", "Plate", "Well","Region","Type"),
                     regex = "([:alpha:]+_\\d+)_(\\d+)-([A-H]1?\\d)[fr]?-?([:alnum:]*)\\.([:alnum:]+).+") %>%
  mutate(Type = ifelse(Type == "trim" & str_length(Region) > 0,
                       "itsx",
                       Type)) %>%
  group_by(Seq.Run, Region, Type) %>%
  summarize(reads = sum(reads)) %>%
  spread(key = "Type", value = "reads") %>%
  select(Seq.Run, trim, Region, itsx, qfilt) %>%
  group_by(Seq.Run) %>%
  mutate(trim = na.omit(trim)) %>%
  filter(all(is.na(itsx)) | !is.na(itsx)) %>%
  ungroup()

demux.counts <- read_lines(file.path(data.dir, "demux.counts")) %>%
  str_match("([^:]+): (\\d+) sequences ([^(]+)( \\(([FR]): (\\d+), ([FR]): (\\d+)\\))?\\.") %>%
  magrittr::extract(,c(2,3,4,6,7,8, 9)) %>%
  set_colnames(c("file", "reads", "type", "d1", "n1", "d2", "n2")) %>%
  as_tibble() %>%
  mutate_at(c("reads", "n1", "n2"), as.integer) %>%
  mutate(fwd = case_when(!is.na(d1) & d1 == "F" ~ n1,
                         !is.na(d2) & d2 == "F" ~ n2,
                         TRUE ~ NA_integer_),
         rev = case_when(!is.na(d1) & d1 == "R" ~ n1,
                         !is.na(d2) & d2 == "R" ~ n2,
                         TRUE ~ NA_integer_)) %>%
  select(-(d1:n2)) %>%
  mutate(dataset = map(file, str_extract, datasets$Dataset) %>%
           map_chr(purrr::compose(dplyr::first, sort, unique)),
         seq.run = map(file, str_extract, datasets$Seq.Run) %>%
           map_chr(purrr::compose(dplyr::first, sort, unique)),
         seq.plate = map(file, str_extract, paste0(datasets$Dataset, "-[0-9]{3}")) %>%
           map_chr(purrr::compose(dplyr::first, sort, unique))) %>%
  group_by(dataset, seq.run, seq.plate,type) %>%
  summarize_at(c("reads", "fwd", "rev"), sum) %>%
  ungroup() %>%
  mutate(type = recode(type,
                       "with at least one tag match" = "any.tag",
                       "match at least 90% of tag length" = "tag.cover",
                       "with at most 3 tag mismatches" = "tag.score",
                       "with no more than one distinct tag in each direction" = "identifiable",
                       "with tags in both directions" = "both.tags",
                       "with tags appearing in correct order" = "tag.order")) %>%
  gather(key = "dir", value = "reads", reads, fwd, rev) %>%
  mutate_at("dir", str_replace, "^reads$", "") %>%
  tidyr::unite("type", type, dir, sep = ".") %>%
  spread(key = "type", value = "reads") %>%
  set_names(str_replace(names(.), "\\.$", "")) %>%
  keep(~!all(is.na(.))) %>%
  select(dataset, starts_with("any.tag"), starts_with("tag.cover"),
         starts_with("tag.score"), starts_with("identifiable"), both.tags, tag.order) %>%
  left_join(select(counts, dataset, original, demux) %>%
              filter(complete.cases(.)) %>%
              unique()) %>%
  select(dataset, original, any.tag:tag.order, demux) %>%
  left_join(select(counts, dataset, region, ITSx, trim))

dada.counts <-
  demux.counts %>%
  left_join(select(datasets, dataset = Dataset, Seq.Run)) %>%
  mutate(file = glue("{data.dir}/{dataset}_{Seq.Run}.dada.seqtable.rds"),
         file = ifelse(is.na(region),
                       file,
                       str_replace(file, "\\.dada", glue(".{region}.dada"))),
         seq.tab = map(file, readRDS),
         assigned = map_int(seq.tab, sum),
         n_ASV = map_int(seq.tab, ncol),
         file = str_replace(file, "\\.dada\\.seqtable\\.rds",
                            ".dada.nochim.rds"),
         nochim = map(file, readRDS),
         nochim.reads = map_int(nochim, sum),
         nochim.ASV = map_int(nochim, ncol)) %>%
  select(-seq.tab, -file, -nochim)
         
dada.counts
```

## ASV correspondences

```{r eval = FALSE}
s.pb.seqs <- readRDS(glue("{data.dir}/short-pacbio_pb_483.dada.nochim.rds")) %>%
  colSums %>%
  tibble(seq = names(.),
         pb.reads = .)
s.ion.seqs <- readRDS(glue("{data.dir}/short-ion_is_057.dada.nochim.rds")) %>%
  colSums %>%
  tibble(seq = names(.),
         ion.reads = .)

(crosstab <- full_join(s.pb.seqs, s.ion.seqs, by = "seq") %>%
  mutate(len = str_length(seq)) %>%
  replace_na(list(pb.reads = 0, ion.reads = 0))) %>%
  ggplot(aes(x = ion.reads, y = pb.reads, color = len)) +
  geom_point() +
  scale_y_log10() +
  scale_x_log10()
```

- IonTorrent reads which match a PacBio ASV: ` filter(crosstab, pb.reads > 0) %$% sum(ion.reads)`
- IonTorrent reads which do NOT match PacBio: ` filter(crosstab, pb.reads == 0) %$% sum(ion.reads)`
- PacBio reads which match an IonTorrent ASV: ` filter(crosstab, ion.reads > 0) %$% sum(pb.reads)`
- PacBio reads which do NOT match IonTorrent: ` filter(crosstab, ion.reads == 0) %$% sum(pb.reads)`

```{r eval = FALSE}
crosstab %>% arrange(pb.reads, ion.reads) %>%
  write.csv(file.path(data.dir, "pb_vs_ion_ASVs.csv"))
```

```{r eval = FALSE}
demux.counts %>%
  select(dataset, region) %>%
  left_join(select(datasets, dataset = Dataset, Seq.Run)) %>%
  mutate(file = glue("{data.dir}/{dataset}_{Seq.Run}.dada.taxonomy.rds"),
         file = ifelse(is.na(region),
                       file,
                       str_replace(file, "\\.dada", glue(".{region}.dada")))) %>%
  filter(file.exists(file)) %>%
  mutate(tax = map(file, readRDS)) %>%
  unnest %>%
  filter(str_detect(Taxonomy, "Inocybe")) %>%
  mutate(nreads = rowSums(select_if(., is.integer), na.rm = TRUE)) %>%
  arrange(desc(nreads)) %>%
  select(dataset, region, nreads, Taxonomy, seq) %>%
  mutate(name = paste(dataset, region, substr(map_chr(seq, digest::digest, algo = "sha1"), 1, 8), sep = "_")) %$%
  set_names(seq, name) %>%
  DNAStringSet(use.names = TRUE) %>%
  writeFasta(file.path(data.dir, "inocybe.fasta"))

`short-ion_is_057.dada.nochim` %>%
  colnames() %>%
  set_names(paste0("seq", seq_along(.))) %>%
  DNAStringSet(use.names = TRUE) %>%
  writeFasta(file.path(data.dir, "short-ion.fasta"))
```

