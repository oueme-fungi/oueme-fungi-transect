# Generate a makefile to 
library(magrittr)
library(tidyverse)
library(glue)
library(assertthat)
library(here)

if (interactive()) {
  base.dir <- str_extract(getwd(), ".+oueme-fungi-transect")
  raw.dir <- file.path(base.dir, "raw_data")
  seq.dir <- here("sequences")
  demux.dir <- file.path(seq.dir, "demux")
  data.dir <- file.path(base.dir, "data")
  lab.dir <- file.path(data.dir, "lab_setup")
  dataset.file <- file.path(lab.dir, "datasets.csv")
  target <- file.path(base.dir, "demux.make")
  splits <- expand.grid(letters, letters) %>%
    glue_data("x{Var2}{Var1}") %>%
    magrittr::extract(1:4)
} else {
  target <- Sys.getenv("TARGETLIST")
  base.dir <- Sys.getenv("BASEDIR")
  raw.dir <- Sys.getenv("RAWDIR")
  demux.dir <- Sys.getenv("DEMUXDIR")
  lab.dir <- Sys.getenv("LABDIR")
  dataset.file <- Sys.getenv("DATASET")
  splits <- Sys.getenv("SPLITS") %>%
    str_split(" ") %>%
    unlist
  if (dirname(target) == ".") target <- file.path(base.dir, basename(target))
}

cat(glue("Base directory: {base.dir}",
         "Lab setup directory: {lab.dir}",
         "Datasets file: {dataset.file}",
         "Splits: {paste(splits, collapse = ' ')}",
         "Target file: {target}",
         .sep = "\n"), "\n\n")

assert_that(is.string(target),
            file.exists(dataset.file))

cat("#############################",
    "# Generated by make_demux.R #",
    "# Do not modify!            #",
    "#############################",
    "",
    "# For each sequencing library, constructs a directory which contains",
    "# a separate file for each multiplexed sample (which may be empty).",
    "# The directory also contains a timestamp file, whose recipe actually",
    "# creates each of these files.",
    "# Each of the files also depends on the timestamp file.",
    "# The recipe will be triggered if:",
    "#   - any of the files is missing",
    "#   - any of the files has been modified since the last timestamp",
    "#   - any of the prerequisite files has been modified since the last build",
    "",
    sep = "\n",
    file = target)

# Data comes from two sources:
# Pacbio RSII raw files (*.ba[sx].h5)
# IonTorrent demultiplexed files (IonXpress_XXX_rawlib.basecaller.bam)
# Pacbio files need:
#   -convert to bam format (in Makefile)
#   -circular consensus calling (in Makefile)
#   -combine all movies from each sequencing run into one file (in Makefile)
#   -convert to fastq.gz
#   -demultiplex and trim adapters
# IonTorrent files need:
#   -trim adapters
# After these steps are done, all files can be treated the same:
#   - preliminary pooled dereplication
#   - ITSx to extract regions of interest from the preliminary derep
#   - Apply the ITSx results to the fastq files
#   - quality filter
#   - second dereplication
#   - denoising (dada2)
#   - chimera checking (within region)
#   - taxonomic assignment



# find potential source files
datasets <- read_csv(dataset.file) %>%
  mutate(Regions = str_split(Regions, ",") %>%
           map(trimws)) %>%
  unnest(Regions) %>%
  mutate(Plate = map(Runs, seq, from = 1)) %>%
  unnest(Plate) %>%
  mutate(Plate = formatC(Plate, width = 3, flag = "0"),
         Seq.Plate = glue("{Seq.Run}_{Plate}"),
         Regions = as.character(Regions) %>%
           paste0(".", .) %>%
           str_replace(fixed(".NA"), ""),
         dada.root = glue("$(DATADIR)/{Seq.Plate}{Regions}.dada"),
         dada.file = glue("{dada.root}.Rdata"),
         dadamap.file = glue("{dada.root}.dadamap.rds"),
         seqtable.file = glue("{dada.root}.seqtable.rds"),
         nochim.file = glue("{dada.root}.nochim.rds"),
         taxonomy.file = glue("{dada.root}.taxonomy.rds"),
         reference.file = case_when(Regions == ".LSU" ~ "lsu_ref.fasta.gz",
                                    TRUE ~ "its_ref.fasta.gz"))

datasets %>%
  with(paste0("dada: ",
              paste(dadamap.file, seqtable.file, nochim.file,
                    collapse = ' \\\n      ',
                    sep = ' \\\n      '))) %>%
  cat("\n\n", sep = "", file = target, append = TRUE)

datasets %>%
  with(paste0("taxonomy: ",
              paste(taxonomy.file, collapse = ' \\\n          '))) %>%
  cat("\n\n", sep = "", file = target, append = TRUE)

datasets %>%
  glue_data("{taxonomy.file}: {reference.file}") %>%
  glue_collapse(sep = "\n") %>%
  cat("\n\n", sep = "", file = target, append = TRUE)

ion.datasets <- datasets %>%
  filter(Tech == "Ion") %>%
  mutate(PlateKey = map(file.path(lab.dir, PlateKey),
                        read_csv)) %>%
  unnest(PlateKey) %>%
  mutate(
    tag.fwd = str_extract(tag.fwd, "\\d+$") %>%
      as.integer %>%
      formatC(width = 3, flag = "0"),
    rawfile = glue("IonXpress_{tag.fwd}_rawlib.basecaller.bam") %>%
      map(list.files, path = raw.dir, recursive = TRUE) %>%
      invoke_map_chr(.f = paste, collapse = " "),
    demuxfile = glue("$(DEMUXDIR)/{Seq.Plate}_{well}.demux.fastq.gz"),
    trimfile = glue("$(TRIMDIR)/{Seq.Plate}_{well}.trim.fastq.gz")) %>%
  filter(str_length(rawfile) > 0)

ion.datasets %>%
  with(paste0("ion-raw: ",
              paste(demuxfile, collapse = ' \\\n         '))) %>%
  cat("\n\n", sep = "", file = target, append = TRUE)

ion.datasets %>%
  glue_data("{demuxfile}: $(RAWDIR)/{rawfile}",
            "\t$(BAM2FASTQ)", .sep = "\n", .trim = FALSE) %>%
  glue_collapse(sep = "\n") %>%
  cat("\n\n", sep = "", file = target, append = TRUE)

ion.datasets %>%
  with(paste0("ion-trim: ",
              paste(trimfile, collapse = ' \\\n          '))) %>%
  cat('\n\n', sep = "", file = target, append = TRUE)

ion.datasets %$%
  unique(Seq.Run) %>%
  glue("ION_SEQRUNS:={paste0(sr, collapse = ' ')}", sr = .) %>%
  cat('\n\n', sep = "", file = target, append = TRUE)

datasets %<>%
  mutate(rootdir = file.path(raw.dir, Dataset, Seq.Run),
         file = map2(rootdir,
                     glue("({Seq.Run}_\\d+\\.reads_of_insert\\.fastq\\.gz|^rawlib.basecaller.bam)"),
                     list.files,
                     recursive = TRUE) %>%
           # don't include any that have already been split
           map(str_detect,
               pattern = "-(x[a-z][a-z])\\.fasta\\.gz"),
         rootdir = str_replace(rootdir, fixed(raw.dir), "$(RAWDIR)")) %>%
  unnest(file) %>%
  mutate(Stem = str_replace(file, fixed(".reads_of_insert.fastq.gz"), ""),
         Stem = str_replace(Stem, "_?rawlib\\.basecaller\\.bam", ""),
         InFile = str_replace(file, fixed(".bam"), ".fastq.gz"),
         Plate = str_match(Stem, glue("{Seq.Run}_(\\d+)$"))[,2],
         Plate = replace_na(Plate, "001"),
         Plate = glue("{Dataset}-{Plate}"),
         blastdb.fwd = glue("$(TAG_ROOT)/{Forward}"),
         blastdb.rev = glue("$(TAG_ROOT)/{Reverse}"))

datasets %>%
  with(paste("data/fastq.counts:",
             paste(unique(file.path(rootdir, InFile)),
                   collapse = " \\\n                  "))) %>%
  cat("\n\n", sep = "", file = target, append = TRUE)

#Instructions to demultiplex
#This needs to be done once per sequence library.
datasets %>%
  mutate_at("InFile", str_replace, "\\.fastq\\.gz", "-x%.fastq.gz") %>%
  mutate(demux.flag = glue("$(DEMUXDIR)/.{Plate}-x%")) %>%
  glue_data(
    "{demux.flag}: export BLASTDB_FWD={blastdb.fwd}",
    "{demux.flag}: export BLASTDB_REV={blastdb.rev}",
    "{demux.flag}: export PLATE={Plate}",
    "{demux.flag}: export SHARD=x$*",
    "{demux.flag}: demultiplex_all.R |",
    "  {rootdir}/{InFile} |",
    "  {blastdb.fwd} |",
    "  {blastdb.rev} |",
    "  $(TAG_ROOT)/{Forward}.fasta |",
    "  $(TAG_ROOT)/{Reverse}.fasta |",
    "  $(LABDIR)/{PlateKey} |",
    "  packrat",
    "\t$(DEMUX)",
            .sep = "\n") %>%
  unique %>%
  glue_collapse(sep = "\n\n") %>%
  str_replace_all(fixed("|\n"), "\\\n") %>%
  cat("\n\n", sep = "", file = target, append = TRUE)

datasets %<>%
  mutate(shard = list(splits)) %>%
  unnest(shard) %>%
  mutate(InFile = str_replace(InFile, fixed("-x%.fastq.gz"), glue("-{shard}.fastq.gz")))

datasets %>%
  with(paste(".INTERMEDIATE:",
             glue("$(DEMUXDIR)/.{Plate}-{shard}") %>%
               unique %>%
               glue_collapse(sep = " \\\n                "))) %>%
  cat("\n\n", sep = "", file = target, append = TRUE)

# List of groups which need to be extracted.
datasets %<>%
  left_join(select(., PlateKey) %>%
              unique %>%
              mutate(KeyData = file.path(lab.dir, PlateKey),
                     KeyData = map(KeyData, read_csv)) %>%
              unnest(KeyData),
            by = "PlateKey") %>%
  mutate(OutFile = glue("{file.path('$(DEMUXDIR)', Plate)}_{well}-{shard}.fastq.gz"),
         OutFile.wild = str_replace(OutFile, fixed(shard), "x%"))

datasets %>% glue_data("{OutFile.wild}: $(DEMUXDIR)/.{Plate}-x% ;",
                       .sep = "\n",
                       .trim = FALSE) %>%
  unique %>%
  glue_collapse(sep = "\n\n") %>%
  cat("\n", ., file = target, append = TRUE, sep = "")


datasets %>%
  mutate(demux.file = str_replace(OutFile.wild, fixed("-x%"), "")) %>%
  select(demux.file, OutFile) %>%
  unique() %>%
  group_by(demux.file) %>%
  summarize(shard.file = paste0(OutFile, collapse = " ")) %>%
  glue_data("data/fastq.counts: {demux.file}",
            "demultiplex: {demux.file}",
            ".PRECIOUS: {demux.file}", #demultiplexing is slow
            ".INTERMEDIATE: {shard.file}",
            "{demux.file}: {shard.file}",
            "\t$(UNSPLIT)",
            .sep = "\n",
            .trim = FALSE) %>%
  glue_collapse(sep = "\n\n") %>%
  cat("\n", ., file = target, append = TRUE, sep = "")

datasets %>%
  mutate(region.file = str_replace(OutFile.wild, fixed(glue("-x%")),
                                   Regions)) %>%
  select(region.file, dada.file) %>%
  unique %>%
  mutate(trim.file = str_replace(region.file,
                                fixed("$(DEMUXDIR)"),
                                "$(TRIMDIR)"),
         trim.file = str_replace(trim.file,
                                fixed(".fastq.gz"),
                                ".trim.fastq.gz")) %>%
  glue_data("data/fastq.counts: {trim.file} {region.file}",
            ".PRECIOUS: {region.file}", #ITSx is slow
            "trim: {trim.file}",
            # "{trim.file}: {region.file}",
            "{dada.file}: {trim.file}",
            .sep = "\n",
            .trim = FALSE) %>%
  glue_collapse(sep = "\n\n") %>%
  cat("\n", ., file = target, append = TRUE, sep = "")
