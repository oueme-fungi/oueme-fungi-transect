---
title: "Filter check"
output: beamer_presentation
---

```{r setup}
# source("install_packages.R")

library(magrittr)
library(tidyverse)
library(glue)
library(Biostrings)
library(ShortRead)
library(ggplot2)

#if (interactive()) {
  base.dir <- getwd() %>%
    str_extract(".*oueme-fungi-transect")
  data.dir <- file.path(base.dir, "data")
  lab.dir <- file.path(data.dir, "lab_setup")
  seq.dir <- file.path(base.dir, "raw_data")
  dataset.file <- file.path(lab.dir, "datasets.csv")
  datasets <- read_csv(dataset.file)
  
  reads <- datasets %>%
    mutate(demux.dir = file.path(seq.dir, Dataset, Seq.Run, "demultiplex"),
           files = map(demux.dir, list.files, pattern = "*.fastq.gz",
                       full.names = TRUE)) %>%
    unnest() %>%
    mutate(filesize = file.size(files)) %>%
    filter(filesize > 0) %>%
    mutate(fastq = map(files, readFastq),
           eexp = map(fastq, ~ 10^(-1 * as(.@quality, "matrix")/10) %>%
                        rowSums(na.rm = TRUE)),
           length = map(fastq, width)) %>%
    select(-fastq) %>%
    unnest %>%
    mutate(erate = eexp/length)
#}
```

```{r}
library("scales")
reverselog_trans <- function(base = exp(1)) {
    trans <- function(x) -log(x, base)
    inv <- function(x) base^(-x)
    trans_new(paste0("reverselog-", format(base)), trans, inv, 
              log_breaks(base = base), 
              domain = c(1e-100, Inf))
}

ggplot(reads, aes(x = erate, group = Dataset, color = Dataset)) +
  geom_step(aes(y = 1- ..y..), stat = "ecdf") +
  scale_x_continuous(name = "Expected number of errors per base",
                     trans = reverselog_trans(10)) +
  scale_y_continuous(name = "Fraction passing")

ggplot(reads, aes(x = eexp, group = Dataset, color = Dataset)) +
  geom_step(aes(y = 1- ..y..), stat = "ecdf") +
  scale_x_continuous(name = "Expected number of errors",
                     trans = reverselog_trans(10)) +
  scale_y_continuous(name = "Fraction passing")

ggplot(reads, aes(x = length, group = Dataset, color = Dataset)) +
  geom_step(aes(y = 1- ..y..), stat = "ecdf") +
  scale_x_log10(name = "Length (bp)") +
  scale_y_continuous(name = "Fraction Greater than length")
  
```
```{r}
counts <- read_csv(file.path(data.dir, "fastq.counts"), col_names = c("file", "reads"))
counts %<>% mutate(dataset = map(file, str_extract, datasets$Dataset) %>%
                     map_chr(purrr::compose(dplyr::first, sort, unique)),
                   seq.run = map(file, str_extract, datasets$Seq.Run) %>%
                     map_chr(purrr::compose(dplyr::first, sort, unique)),
                   well = str_extract(file, "[A-H]\\d\\d?"),
                   shard = str_extract(file, "\\bx[a-z][a-z]\\b"),
                   is.shard = !is.na(shard),
                   region = str_extract(file, "(ITS[12]|LSU)"),
                   is.trim = str_detect(file, "trim"),
                   is.demux = is.na(region) & !is.trim & !is.na(well),
                   type = ifelse(is.trim, "trim",
                                 ifelse(!is.na(region), "ITSx",
                                        ifelse(is.demux, "demux",
                                               "original"))),
                   plate = str_extract(file, "00\\d")) %>%
  group_by(dataset, type, region, is.shard) %>%
  summarize(reads = sum(reads)) %>%
  ungroup() %>%
  select(-is.shard) %>%
  unique() %>%
  spread(key = "type", value = "reads") %>%
  select(dataset, original, demux, region, ITSx, trim) %>%
  filter(!is.na(dataset)) %>%
  group_by(dataset) %>%
  mutate(original = na.omit(original),
         demux = na.omit(demux)) %>%
  filter(all(is.na(region)) | !is.na(region))

demux.counts <- read_lines(file.path(data.dir, "demux.counts")) %>%
  str_match("([^:]+): (\\d+) sequences (.+)") %>%
  magrittr::extract(,-1) %>%
  set_colnames(c("file", "reads", "type")) %>%
  as_tibble() %>%
  mutate(dataset = map(file, str_extract, datasets$Dataset) %>%
                     map_chr(purrr::compose(dplyr::first, sort, unique)),
                   seq.run = map(file, str_extract, datasets$Seq.Run) %>%
                     map_chr(purrr::compose(dplyr::first, sort, unique))) %>%
  group_by(dataset, seq.run, type) %>%
  summarize(reads = sum(as.integer(reads))) %>%
  ungroup() %>%
  mutate(type = recode(type,
                       "with at least one tag match. " = "any.tag",
                       "match at least 90% of tag length. " = "tag.cover",
                       "with at most 3 tag mismatches. " = "tag.score",
                       "with no more than one distinct tag in each direction. " = "identifiable",
                       "with tags in both directions. " = "both.tags",
                       "with tags appearing in correct order. " = "tag.order")) %>%
  spread(key = "type", value = "reads") %>%
  select(dataset, any.tag, tag.cover, tag.score, identifiable, both.tags, tag.order) %>%
  left_join(select(counts, dataset, original, demux) %>% filter(complete.cases(.))) %>%
  select(dataset, original, any.tag:tag.order, demux) %>%
  left_join(select(counts, dataset, region, ITSx, trim))

d
short.pacbio <- new.env()
load(file.path(data.dir, "short-pacbio_pb_483.asv.Rdata"), envir = short.pacbio)
remove("derep", envir = short.pacbio)
assign("seq.tab", dada2::makeSequenceTable(short.pacbio$asv), envir = short.pacbio)

long.pacbio.ITS1 <- new.env()
load(file.path(data.dir, "long-pacbio_pb_500.ITS1.asv.Rdata"), envir = long.pacbio.ITS1)
remove("derep", envir = long.pacbio.ITS1)
assign("seq.tab", dada2::makeSequenceTable(long.pacbio.ITS1$asv), envir = long.pacbio.ITS1)

long.pacbio.ITS2 <- new.env()
load(file.path(data.dir, "long-pacbio_pb_500.ITS2.asv.Rdata"), envir = long.pacbio.ITS2)
remove("derep", envir = long.pacbio.ITS2)
assign("seq.tab", dada2::makeSequenceTable(long.pacbio.ITS2$asv), envir = long.pacbio.ITS2)

long.pacbio.LSU <- new.env()
load(file.path(data.dir, "long-pacbio_pb_500.LSU.asv.Rdata"), envir = long.pacbio.LSU)
remove("derep", envir = long.pacbio.LSU)
assign("seq.tab", dada2::makeSequenceTable(long.pacbio.LSU$asv), envir = long.pacbio.LSU)

short.ion <- new.env()
load(file.path(data.dir, "short-ion_is_057.asv.Rdata"), envir = short.ion)
remove("derep", envir = short.ion)
assign("seq.tab", dada2::makeSequenceTable(short.ion$asv), envir = short.ion)

dadacounts <- tribble( ~ dataset, ~region, ~assigned, ~asv,
                       "short-pacbio", NA, sum(short.pacbio$seq.tab), ncol(short.pacbio$seq.tab),
                       "long-pacbio", "ITS1", sum(long.pacbio.ITS1$seq.tab), ncol(long.pacbio.ITS1$seq.tab),
                       "long-pacbio", "ITS2", sum(long.pacbio.ITS2$seq.tab), ncol(long.pacbio.ITS2$seq.tab),
                       "long-pacbio", "LSU", sum(long.pacbio.LSU$seq.tab), ncol(long.pacbio.LSU$seq.tab),
                       "short-ion", NA, sum(short.ion$seq.tab), ncol(short.ion$seq.tab))

demux.counts %>% left_join(dadacounts) %>%
  filter(!is.na(assigned))
```

