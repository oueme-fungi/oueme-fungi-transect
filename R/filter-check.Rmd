---
title: "Filter check"
output: beamer_presentation
---

```{r setup}
# source("install_packages.R")

library(magrittr)
library(tidyverse)
library(glue)
library(Biostrings)
library(ShortRead)
library(ggplot2)
library("scales")

#if (interactive()) {
  base.dir <- getwd() %>%
    str_extract(".*oueme-fungi-transect")
  data.dir <- file.path(base.dir, "data")
  lab.dir <- file.path(data.dir, "lab_setup")
  seq.dir <- file.path(base.dir, "raw_data")
  dataset.file <- file.path(lab.dir, "datasets.csv")
  datasets <- read_csv(dataset.file)
  
  reads <- datasets %>%
    mutate(demux.dir = file.path(seq.dir, Dataset, Seq.Run, "demultiplex"),
           files = map(demux.dir, list.files, pattern = "*.fastq.gz",
                       full.names = TRUE)) %>%
    unnest() %>%
    mutate(filesize = file.size(files)) %>%
    filter(filesize > 0) %>%
    mutate(fastq = map(files, readFastq),
           eexp = map(fastq, ~ 10^(-1 * as(.@quality, "matrix")/10) %>%
                        rowSums(na.rm = TRUE)),
           length = map(fastq, width)) %>%
    select(-fastq) %>%
    unnest %>%
    mutate(erate = eexp/length)
#}
```

```{r}
reverselog_trans <- function(base = exp(1)) {
    trans <- function(x) -log(x, base)
    inv <- function(x) base^(-x)
    trans_new(paste0("reverselog-", format(base)), trans, inv, 
              log_breaks(base = base), 
              domain = c(1e-100, Inf))
}

ggplot(reads, aes(x = erate, group = Dataset, color = Dataset)) +
  geom_step(aes(y = 1- ..y..), stat = "ecdf") +
  scale_x_continuous(name = "Expected number of errors per base",
                     trans = reverselog_trans(10)) +
  scale_y_continuous(name = "Fraction passing")

ggplot(reads, aes(x = eexp, group = Dataset, color = Dataset)) +
  geom_step(aes(y = 1- ..y..), stat = "ecdf") +
  scale_x_continuous(name = "Expected number of errors",
                     trans = reverselog_trans(10)) +
  scale_y_continuous(name = "Fraction passing")

ggplot(reads, aes(x = length, group = Dataset, color = Dataset)) +
  geom_step(aes(y = 1- ..y..), stat = "ecdf") +
  scale_x_log10(name = "Length (bp)") +
  scale_y_continuous(name = "Fraction Greater than length")
  
```
```{r}
counts <- read_csv(file.path(data.dir, "fastq.counts"), col_names = c("file", "reads"))
counts %<>% mutate(dataset = map(file, str_extract, datasets$Dataset) %>%
                     map_chr(purrr::compose(dplyr::first, sort, unique)),
                   seq.run = map(file, str_extract, datasets$Seq.Run) %>%
                     map_chr(purrr::compose(dplyr::first, sort, unique)),
                   well = str_extract(file, "[A-H]\\d\\d?"),
                   shard = str_extract(file, "\\bx[a-z][a-z]\\b"),
                   is.shard = !is.na(shard),
                   region = str_extract(file, "(ITS[12]|LSU)"),
                   is.trim = str_detect(file, "trim"),
                   is.demux = is.na(region) & !is.trim & !is.na(well),
                   type = ifelse(is.trim, "trim",
                                 ifelse(!is.na(region), "ITSx",
                                        ifelse(is.demux, "demux",
                                               "original"))),
                   plate = str_extract(file, "00\\d")) %>%
  group_by(dataset, type, region, is.shard) %>%
  summarize(reads = sum(reads)) %>%
  ungroup() %>%
  select(-is.shard) %>%
  unique() %>%
  spread(key = "type", value = "reads") %>%
  select(dataset, original, demux, region, ITSx, trim) %>%
  filter(!is.na(dataset)) %>%
  group_by(dataset) %>%
  mutate(original = na.omit(original),
         demux = na.omit(demux)) %>%
  filter(all(is.na(region)) | !is.na(region)) %>%
  ungroup()

demux.counts <- read_lines(file.path(data.dir, "demux.counts")) %>%
  str_match("([^:]+): (\\d+) sequences ([^(]+)( \\(([FR]): (\\d+), ([FR]): (\\d+)\\))?\\.") %>%
  magrittr::extract(,c(2,3,4,6,7,8, 9)) %>%
  set_colnames(c("file", "reads", "type", "d1", "n1", "d2", "n2")) %>%
  as_tibble() %>%
  mutate_at(c("reads", "n1", "n2"), as.integer) %>%
  mutate(fwd = case_when(!is.na(d1) & d1 == "F" ~ n1,
                         !is.na(d2) & d2 == "F" ~ n2,
                         TRUE ~ NA_integer_),
         rev = case_when(!is.na(d1) & d1 == "R" ~ n1,
                         !is.na(d2) & d2 == "R" ~ n2,
                         TRUE ~ NA_integer_)) %>%
  select(-(d1:n2)) %>%
  mutate(dataset = map(file, str_extract, datasets$Dataset) %>%
                     map_chr(purrr::compose(dplyr::first, sort, unique)),
                   seq.run = map(file, str_extract, datasets$Seq.Run) %>%
                     map_chr(purrr::compose(dplyr::first, sort, unique))) %>%
  group_by(dataset, seq.run, type) %>%
  summarize_at(c("reads", "fwd", "rev"), sum) %>%
  ungroup() %>%
  mutate(type = recode(type,
                       "with at least one tag match" = "any.tag",
                       "match at least 90% of tag length" = "tag.cover",
                       "with at most 3 tag mismatches" = "tag.score",
                       "with no more than one distinct tag in each direction" = "identifiable",
                       "with tags in both directions" = "both.tags",
                       "with tags appearing in correct order" = "tag.order")) %>%
  gather(key = "dir", value = "reads", reads, fwd, rev) %>%
  mutate_at("dir", str_replace, "^reads$", "") %>%
  tidyr::unite("type", type, dir, sep = ".") %>%
  spread(key = "type", value = "reads") %>%
  set_names(str_replace(names(.), "\\.$", "")) %>%
  keep(~!all(is.na(.))) %>%
  select(dataset, starts_with("any.tag"), starts_with("tag.cover"),
         starts_with("tag.score"), starts_with("identifiable"), both.tags, tag.order) %>%
  left_join(select(counts, dataset, original, demux) %>%
              filter(complete.cases(.)) %>%
              unique()) %>%
  select(dataset, original, any.tag:tag.order, demux) %>%
  left_join(select(counts, dataset, region, ITSx, trim))

dada.counts <-
  demux.counts %>%
  left_join(select(datasets, dataset = Dataset, Seq.Run)) %>%
  mutate(file = glue("{data.dir}/{dataset}_{Seq.Run}.dada.seqtable.rds"),
         file = ifelse(is.na(region),
                       file,
                       str_replace(file, "\\.dada", glue(".{region}.dada"))),
         seq.tab = map(file, readRDS),
         assigned = map_int(seq.tab, sum),
         n_ASV = map_int(seq.tab, ncol)) %>%
  select(-data, -seq.tab, -file)
         
dada.counts
```

